<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
  <title>Visual Analytics Assignment</title>

  <meta property="description" itemprop="description" content="Exploring and Protoyping visualizations methods for Understanding News Corpus."/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2021-04-11"/>
  <meta property="article:created" itemprop="dateCreated" content="2021-04-11"/>
  <meta name="article:author" content="Atticus Foo"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Visual Analytics Assignment"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Exploring and Protoyping visualizations methods for Understanding News Corpus."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Visual Analytics Assignment"/>
  <meta property="twitter:description" content="Exploring and Protoyping visualizations methods for Understanding News Corpus."/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Visual Analytics Assignment"]},{"type":"character","attributes":{},"value":["Exploring and Protoyping visualizations methods for Understanding News Corpus.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Atticus Foo"]},{"type":"character","attributes":{},"value":["https://public.tableau.com/profile/atticusfoo#!/"]}]}]},{"type":"character","attributes":{},"value":["04-11-2021"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["toc","toc_depth","self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[6]},{"type":"logical","attributes":{},"value":[false]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["Animations/Archive/circle treemap.html","Animations/Archive/sgx3.html","Animations/Archive/test2.html","Animations/Archive/test4.html","Animations/Archive/testtt.html","Animations/Archive/Treemap.html","Animations/bing","Animations/CircleTreemap.html","Animations/ExampleD3partitionR.gif","Animations/ldavis/d3.v3.js","Animations/ldavis/index.html","Animations/ldavis/lda.css","Animations/ldavis/lda.json","Animations/ldavis/ldavis.js","Animations/nocorrelation","Animations/r-politics-three-months.txt","Animations/sentiment all media all year","Animations/sentiment by topic","Animations/sentiment media all year","Animations/sgx","Animations/SGX5.html","Animations/stmVignette.pdf","Animations/Sunburst.html","Animations/time set visulization.PNG","Animations/Treemap.html","CircleTreemap.html","images/anomaly detection.png","images/cooccurrence.PNG","images/Corporaexplorer1.PNG","images/Corporaexplorer2.PNG","images/D3.gif","images/Data Profiling Report.pdf","images/dataexplorer1.PNG","images/dataexplorer2.PNG","images/dataexplorer3.PNG","images/dataexplorer4","images/EULER DIAGRAM.png","images/EXAMPLE SUNBURST R.png","images/LDA20.PNG","images/LDAVIZ.PNG","images/LDAVIZ2.PNG","images/mlr stock.PNG","images/moasic linear diagram.png","images/modulesketch.jpg","images/newsflow.png","images/newsheader.jpg","images/PRRT DASHBOARD.PNG","images/sentiment analysis","images/sentiment analysis bar.png","images/sentiment analysis by media.png","images/sentiment analysis overall.png","images/sentiment analysis topic","images/sentiment analysis.png","images/sgx.PNG","images/sgx2.PNG","images/temporal iran missiles.png","images/temporal iran.png","images/termite.png","images/TEXT2VECBAR","images/tidytext model.png","images/tidytextlda.png","images/top_topics2.csv","images/trigrams.jfif","images/visualising sets with linear diagrams.png","images/wordclouds are lame.png","images/wordnetwork.PNG","ldavis/d3.v3.js","ldavis/index.html","ldavis/lda.css","ldavis/lda.json","ldavis/ldavis.js","SGX5.html","Sunburst.html","Treemap.html","visual-analytics-assignment_files/anchor-4.2.2/anchor.min.js","visual-analytics-assignment_files/bowser-1.9.3/bowser.min.js","visual-analytics-assignment_files/distill-2.2.21/template.v2.js","visual-analytics-assignment_files/header-attrs-2.7/header-attrs.js","visual-analytics-assignment_files/jquery-1.11.3/jquery.min.js","visual-analytics-assignment_files/popper-2.6.0/popper.min.js","visual-analytics-assignment_files/tippy-6.2.7/tippy-bundle.umd.min.js","visual-analytics-assignment_files/tippy-6.2.7/tippy-light-border.css","visual-analytics-assignment_files/tippy-6.2.7/tippy.css","visual-analytics-assignment_files/tippy-6.2.7/tippy.umd.min.js","visual-analytics-assignment_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="visual-analytics-assignment_files/header-attrs-2.7/header-attrs.js"></script>
  <script src="visual-analytics-assignment_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="visual-analytics-assignment_files/popper-2.6.0/popper.min.js"></script>
  <link href="visual-analytics-assignment_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="visual-analytics-assignment_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="visual-analytics-assignment_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="visual-analytics-assignment_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="visual-analytics-assignment_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="visual-analytics-assignment_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="visual-analytics-assignment_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Visual Analytics Assignment","description":"Exploring and Protoyping visualizations methods for Understanding News Corpus.","authors":[{"author":"Atticus Foo","authorURL":"https://public.tableau.com/profile/atticusfoo#!/","affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2021-04-11T00:00:00.000+08:00","citationText":"Foo, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Visual Analytics Assignment</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>Exploring and Protoyping visualizations methods for Understanding News Corpus.</p></p>
</div>

<div class="d-byline">
  Atticus Foo <a href="https://public.tableau.com/profile/atticusfoo#!/" class="uri">https://public.tableau.com/profile/atticusfoo#!/</a> 
  
<br/>04-11-2021
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#overview-of-problem-statement-difficult-to-sense-make-news-headlines-in-digital-landscape">Overview of Problem Statement: Difficult to sense-make news headlines in digital landscape</a></li>
<li><a href="#project-objective-provide-readers-with-useful-snapshots-of-news-headlines">Project Objective: Provide readers with useful snapshots of news headlines</a></li>
<li><a href="#our-data-source-local-news-reports-in-2020">Our Data Source: Local News Reports in 2020</a></li>
<li><a href="#literature-review">Literature review:</a>
<ul>
<li><a href="#importance-of-analyzing-unstructured-news-data">Importance of analyzing unstructured news data</a></li>
<li><a href="#impact-of-news-media-on-our-lives">Impact of News Media on our lives</a></li>
<li><a href="#impact-of-social-media-and-echo-chambers">Impact of Social Media and Echo Chambers</a></li>
<li><a href="#limited-resources-for-visualising-unstructured-data">Limited resources for visualising unstructured data</a></li>
</ul></li>
<li><a href="#approach">Approach</a>
<ul>
<li><a href="#data-extraction-and-wrangling">1. Data extraction and Wrangling</a>
<ul>
<li><a href="#data-extraction">Data Extraction</a></li>
<li><a href="#data-exploration-before-cleaning">Data Exploration Before Cleaning</a></li>
<li><a href="#scoping-the-dataset">Scoping the dataset</a></li>
<li><a href="#datatext-pre-processing-and-cleaning">DataText Pre-Processing and cleaning</a></li>
</ul></li>
<li><a href="#topic-modeling-methods">2.Topic Modeling Methods</a>
<ul>
<li><a href="#why-latent-dirichlet-allocation-lda">Why Latent Dirichlet Allocation (LDA)</a></li>
<li><a href="#criticisms-of-lda">Criticisms of LDA</a></li>
<li><a href="#different-methods-and-packages-for-lda">Different methods and packages for LDA</a></li>
<li><a href="#issues-faced">Issues faced</a></li>
<li><a href="#package-selected-text2vec">Package Selected: text2Vec</a></li>
<li><a href="#visualizing-results">Visualizing Results</a></li>
</ul></li>
<li><a href="#methods-for-presenting-snapshot">3.Methods for Presenting Snapshot</a>
<ul>
<li><a href="#objective-1-explore---sorting-through-and-identifying-key-events-in-large-corpus-of-news">3.1.<strong>Objective 1: Explore</strong> - Sorting through and identifying key events in large corpus of news</a></li>
<li><a href="#objective-2-discover---providing-greater-detail-and-context-about-a-topic-news-source">3.2.<strong>Objective 2: Discover</strong> - Providing greater detail and context about a topic / news source</a>
<ul>
<li><a href="#using-sentiment">3.2.1 USing Sentiment</a></li>
<li><a href="#using-wordnetworks">3.2.2 USing WordNetworks</a></li>
<li><a href="#using-word-co-occurences">3.2.2 USing Word Co-occurences</a></li>
</ul></li>
<li><a href="#objective-3-detect---providing-alerts-to-unusual-patterns-in-news-analysis">3.4.<strong>Objective 3: Detect</strong> - Providing alerts to unusual patterns in news analysis</a></li>
</ul></li>
</ul></li>
<li><a href="#summary-of-observations-from-exploration-of-r-packages">Summary of observations from exploration of R Packages</a></li>
<li><a href="#proposed-sketch-of-project-module-2-discovering-topics-and-its-context">Proposed Sketch of Project Module 2: Discovering Topics and it’s context</a></li>
<li><a href="#closing-reflections">Closing Reflections</a></li>
</ul>
</nav>
</div>
<div class="layout-chunk" data-layout="m-page">
<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="images/newsheader.jpg" alt="Data Re-presented." width="50%" />
<p class="caption">
Figure 1: Data Re-presented.
</p>
</div>
</div>
<h1 id="overview-of-problem-statement-difficult-to-sense-make-news-headlines-in-digital-landscape">Overview of Problem Statement: Difficult to sense-make news headlines in digital landscape</h1>
<p>Making sense of the news in today’s landscape is extremely difficult because of:</p>
<ol type="1">
<li>The volume of information available to you via digital channels;</li>
<li>Social media bubbles may create echo chambers that only serve you only one aspect of news making it difficult to understand the full context;</li>
<li>News can be manipulated based on phishing (creating duplicates) and inflated engagement metrics campaigns.</li>
</ol>
<p>This can be useful as news headlines can have very real impact on not just personal sense-making but also cause tangible effects. This can be seen from how media reporting can contribute to the public’s understanding of safe distancing measures during COVID-19 to how it can influence share prices on the stock market. The following blogpost is to establish the project’s objectives, explore current practices, and prototype methods in order to help readers navigate the digital news landscape.</p>
<h1 id="project-objective-provide-readers-with-useful-snapshots-of-news-headlines">Project Objective: Provide readers with useful snapshots of news headlines</h1>
<p>As such, the team’s goal is to build an accessible dashboard that can help readers of local news sites (both mainstream and non-mainstream) quickly navigate and understand a large corpus of news. This will be done by applying statistical methods to sort large volumes of unstructured data. The intended result is different snapshots that would allow readers to:</p>
<ol type="1">
<li><strong>[Explore]</strong> Sort through and identify key events in the large corpus of news events by:
<ol type="a">
<li>Time period;</li>
<li>Topic and;</li>
<li>Keyword</li>
</ol></li>
<li><strong>[Discover]</strong> Understand in greater detail the context around each theme and news source by
<ol type="a">
<li>Sentiment and;</li>
<li>Word structure</li>
</ol></li>
<li><strong>[Detect]</strong> Be alerted to unusual patterns
<ol type="a">
<li>Identify anomalous events and articles based on engagement.</li>
</ol></li>
</ol>
<p>As such, while the presentation of the ‘snapshot’ may appear simple, the methods that would derive these insights are not. The approach taken for this project is based on a mixed of deep research of current statistical methods, domain knowledge of the local news reporting landscape and rigorous data wrangling.</p>
<h1 id="our-data-source-local-news-reports-in-2020">Our Data Source: Local News Reports in 2020</h1>
<p>The data selected for analysis is from 1 January 2020 to 31 December 2020. These local news sites are a mix of mainstream (Straits Times, Channel News Asia, AsiaOne) and non-mainstream (Mothership, MustShareNews, The Independent) sites. A few others such as (TODAY Online, The Online Citizen) were initially selected but removed from our observations. This will be explained at the data wrangling phase.</p>
<figure>
<img src="images/PRRT%20DASHBOARD.PNG" alt="Prrt" /><figcaption aria-hidden="true">Prrt</figcaption>
</figure>
<p>Data extracted from <a href="prrt.co">Prrt</a> is extremely useful for the project as it provides an easy tool for the extraction of the article headline, corresponding URL and Facebook Engagement metrics (Likes, Shares and Comments). In the absence of actual webviewership data, Facebook engagement data is often used as a proxy as the dataset is more easily <a href="https://www.facebook.com/journalismproject/news5-facebook-tools-major-news-event-reporting">accessible</a>. Facebook is also arguably the most widely used social media platform in Singapore&gt; it is also still used by major news sites for information dissemination as well as resource for analysis and understanding of the virality of a news article and <a href="https://help.crowdtangle.com/en/articles/4554891-how-nbc-news-uses-crowdtangle-to-source-and-tell-local-stories-on-a-national-level">topic</a>.</p>
<h1 id="literature-review">Literature review:</h1>
<h2 id="importance-of-analyzing-unstructured-news-data">Importance of analyzing unstructured news data</h2>
<p>While preparing for the project, we researched four different areas to understand the key areas that needed to be addressed. The main challenge of the project is that of dealing with large volumes of unstructured data (224,351 news headlines and 2,692,224 observations). There are also limited libraries we can call upon in R as text analytics packages for R on CRAN are limited in number. Visualization packages that avoid simple word cloud comparisons are far fewer in number. This is compounded by the fact that the project is very niche as it is set in the local context, and as such, would have little case study options readily available.</p>
<p>Despite these constraints, the team is of the opinion that the project is a worthy one as there is an increasing need to help navigate the digital news landscape. As mentioned in the earlier section, news can have a very large and tangible impact on our lives and the increasing availability of data visualization tools within the realms of journalism can help readers make sense of the stories that are out there. However, as identified by Data Journalism, there is not enough being done to take advantage of <a href="https://datajournalism.com/read/handbook/two/experiencing-data/data-visualisations-newsroom-trends-and-everyday-engagements">this</a>.</p>
<p>Fortunately, as news media tended to follow standardized schools of reporting (e.g. <a href="https://www.apstylebook.com/">AP style Book</a>), there was research available (predominantly) on different methods used to analyse western media. These methods could then be adopted for analysing Singaporean media. For instance, text cleaning and sentiment analysis could easily adopt the English packages as they were unlikely to contain colloquial lingua franca that was most used on local social networking sites. Furthermore, the use of standardised stylebooks for news reporting would help the Latent Dirichlet Model which the team intends to use, as the model relies on the probabilities of similar words across similar topic distributions.</p>
<h2 id="impact-of-news-media-on-our-lives">Impact of News Media on our lives</h2>
<p>As identified by <a href="https://cpb-us-w2.wpmucdn.com/sites.northeastern.edu/dist/d/53/files/2020/02/CJ_2020_paper_39.pdf">Bhargava, Bishop and Zuckerman</a>, there is clear evidence of the influence of the news media and its news reporting. They posit that building tools can help readers quickly analyse content, influence and the spread of news. In turn, they will be better equipped to respond to the growing impact of visual (and viral) news. This group’s earlier study also demonstrated that mobile app usage frequency can be correlated to news events and reporting (Chee, Nam, Foo 2020).</p>
<p>Kouivunen Niemi and Masoodian echo this in their recent article, visualising narrative patterns in <a href="https://link-springer-com.libproxy.smu.edu.sg/content/pdf/10.1007/s11042-019-08186-9.pdf">online news media</a>. They argue that the new media and its reports can have “widespread repercussions in the public perception of past and present phenomena” and proposed “temporal visualizations for examining differences in media narrative patterns over time and across publications”. This is provide a tool or method to simply to report findings in an “easy to understand but effective way”. They also go further to lament how these type of (text) studies are “almost invariably presented in tables, or using simple graphs such as bar charts or line charts”.</p>
<figure>
<img src="images/cooccurrence.PNG" alt="Co-occurrences across different texts" /><figcaption aria-hidden="true">Co-occurrences across different texts</figcaption>
</figure>
<h2 id="impact-of-social-media-and-echo-chambers">Impact of Social Media and Echo Chambers</h2>
<p>In recent years, increasing amounts of research (the echo chamber effect on <a href="https://www.pnas.org/content/118/9/e2023301118">social media</a> have also point to the dangers of social media companies inadvertently creating <a href="https://edu.gcfglobal.org/en/digital-media-literacy/what-is-an-echo-chamber/1/">echo-chambers</a>in order to maximise engagement metrics. They do this by presenting readers content that they are likely already biased towards, thus increasing the propensity (Platforms like Facebook are designed to profit for human’s <a href="https://www.wired.com/story/facebook-twitter-echo-chamber-confirmation-bias/">confirmation bias</a> that they continue engagement with the <a href="https://www.theguardian.com/science/blog/2017/dec/04/echo-chambers-are-dangerous-we-must-try-to-break-free-of-our-online-bubbles">social media platform</a>.</p>
<p>To combat this, researchers propose that readers pay attention the news source to ensure authenticity and the corresponding engagement metrics in order to determine if an article has been manipulated to reach a wider audience (e.g. when the engagement ratios for a content does not appear to be <a href="https://www.latimes.com/business/technology/story/2019-12-06/social-media-manipulation-nato-research">natural</a>. This happens typically when ‘likes’ or ‘shares’ are mobilised. As such, we intend to provide a range of 6 sources that readers can easily access when they are looking for information related to a topic. They are then able to explore the context surrounding a topic (i.e. sentiment and co-occurring words) and use engagement metrics to identify if there are anomalous articles.</p>
<h2 id="limited-resources-for-visualising-unstructured-data">Limited resources for visualising unstructured data</h2>
<p>A commonly used method for visualising text is the use of <a href="https://towardsdatascience.com/headlines-articles-analysis-and-nlp-4013a66dbac">word clouds</a> . They often aim to represent the most commonly used words in a corpus by size but have limited utility at best (crf. when word clouds are <a href="https://www.keatext.ai/en/blog/artificial-intelligence/3-strengths-and-3-weaknesses-of-word-clouds/">not enough</a>, and mis-representative of the data at [worst]<a href="https://towardsdatascience.com/word-clouds-are-lame-263d9cbc49b7" class="uri">https://towardsdatascience.com/word-clouds-are-lame-263d9cbc49b7</a>). Often, they include common verbs that do very little to explain word in the context of the corpus of data (crf. <a href="https://getthematic.com/insights/word-clouds-harm-insights/#:~:text=Word%20clouds%20lack%20context.,or%20even%20the%20entire%20comment">Why word clouds harm insights</a>.</p>
<figure>
<img src="images/wordclouds%20are%20lame.png" alt="Photo Credit: Shelby Temple" /><figcaption aria-hidden="true">Photo Credit: Shelby Temple</figcaption>
</figure>
<p>Other interesting methods explored for text visualization build on Venn and Euler diagrams.</p>
<figure>
<img src="images/EULER%20DIAGRAM.png" alt="Euler Diagram" /><figcaption aria-hidden="true">Euler Diagram</figcaption>
</figure>
<p>They include work by Rodgers, Stapleton &amp; Chapman (<a href="https://kar.kent.ac.uk/50020/">Visualizing sets with linear diagrams</a> which demonstrate the intersection where words are shared by different sources or topics.</p>
<figure>
<img src="images/linear%20sets.png" alt="Visualizing sets with linear diagrams" /><figcaption aria-hidden="true">Visualizing sets with linear diagrams</figcaption>
</figure>
<p>A similar approach was adopted by Luz and Masood (a comparison of linear and mosaic diagrams for <a href="https://journals.sagepub.com/doi/abs/10.1177/1473871618754343">set visualization</a>.</p>
<figure>
<img src="images/mosaic%20linear%20diagram.png" alt="Comparison of different scalings of mosaic and lienar diagrams" /><figcaption aria-hidden="true">Comparison of different scalings of mosaic and lienar diagrams</figcaption>
</figure>
<p>However, these methods were not entirely applicable for our project as these visualizations benefitted from a small number of documents that could be extensive in length. Our dataset however, consists of over 200,000 documents that were all very short in length (a news headline typically has up to 30 words).</p>
<p>Other than visualising topics and their word occurrences in other texts, we also intended to learn methods to visualise the temporal evolution of news topics as we intended to allow readers to explore how news evolved across a full year in 2020. This, we felt, would be interesting as the COVID-19 pandemic allowed for us to track the evolution of a news topic across nearly 12 months. This was somewhat of an irregularity in news media as the typical news cycle operates on a much shorter cycle of 48 hours (or less). While researching on this, we came across interesting methods used by Sheidin &amp; Lanir (<a href="https://dl.acm.org/doi/10.1145/3030024.3040984">Visualising Spatial-Temporal Evaluation of News Stories</a>.</p>
<figure>
<img src="images/temporal%20iran.png" alt="News of Iran firing ballistic missles around the world" /><figcaption aria-hidden="true">News of Iran firing ballistic missles around the world</figcaption>
</figure>
<p>The visualisation presents an idea for a system that is able to analysis the spread and volume of news episodes across space and time. However, this is not entirely applicable to the dataset used in our project because the number of news sources in the study are low (6) and all based in Singapore. Another mitigating, but more minor factor, is the lack of time data in the dataset.</p>
<h1 id="approach">Approach</h1>
<p>Based on the research, our proposed approach for the project would be to create three separate modules that would allow users to 1) explore the corpus to identify key events 2) understand the key events / topics in greater detail and 3) to be alerted to unusual patterns. While the eventual presentation will appear to be a simple (and ideally effective) report card of the media situation, it will be grounded at the backend by statistical methods and rigorous data wrangling.</p>
<h2 id="data-extraction-and-wrangling">1. Data extraction and Wrangling</h2>
<h3 id="data-extraction">Data Extraction</h3>
<p>As mentioned above, the dataset that we have extracted is taken from <a href="prrt.co">Prrt</a>. This is because Prrt is unique to local news media publishers in Singapore (and Malaysia) and allows us to extract news headlines together with its corresponding social media engagement. For other types of news extraction, there are R packages that offer news headline extraction. These include <a href="https://cran.r-project.org/web/packages/guardianapi/index.html">Guardian API</a> <a href="https://cran.r-project.org/web/packages/MediaNews/index.html">Media News</a> and <a href="https://github.com/koheiw/newsmap">Newsmap</a>.</p>
<p>An interesting package for news extraction and analysis is <a href="https://github.com/koheiw/newsmap">NewsFlow</a> as it allows for tracking of the flows between offline and online news. It is an interesting case study of how quickly news spreads from the offline sphere to the online one, or vice versa.</p>
<figure>
<img src="images/newsflow.png" alt="NewsFlow" /><figcaption aria-hidden="true">NewsFlow</figcaption>
</figure>
<p>However, as the scope of the project is primarily concerned with online news, we will not be able to utilize the NewsFlow package for our analysis.</p>
<h3 id="data-exploration-before-cleaning">Data Exploration Before Cleaning</h3>
<p>Before we started on data cleaning, we want to explore the dataset to identify if there are any potential issues (such as low or missing values) in the dataset. R provides many packages that can help do this (e.g. <a href="https://dplyr.tidyverse.org/reference/summarise.html">Dplyr</a>, <a href="https://indrajeetpatil.github.io/ggstatsplot/articles/web_only/ggbetweenstats.html">GGbetweenstats</a>, <a href="https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html">Data Explorer</a> and <a href="https://cran.r-project.org/web/packages/janitor/index.html">Janitor</a>.</p>
<p>We will use Data Explorer to perform preliminary data exploration, to identify which areas to go into further depth. Data explorer allows for very quick EDA and feature reporting. For this step, we will need to install Tidyverse and DataExplorer.</p>
<pre class="{r}"><code>install.packages(“DataExplorer”, “tidyverse”, dependencies = TRUE)
library(DataExplorer, tidyverse)
#read csv file using tidyverse from your local source folder
media_explore &lt;- read_csv(“Data/all_media.csv”) 
#check data for missing values
data(media_explore) 
plot_missing(media_explore) 
#create a pdf report 
create_report(media_explore) </code></pre>
<figure>
<img src="images/dataexplorer1.PNG" alt="Dataexplorer" /><figcaption aria-hidden="true">Dataexplorer</figcaption>
</figure>
<p>Results from the Data Explorer also show little issues with missing values as the dataset is relatively complete and that the data fields are in the correct data types (e.g. chr and num)</p>
<figure>
<img src="images/dataexplorer2.PNG" alt="Dataexplorer" /><figcaption aria-hidden="true">Dataexplorer</figcaption>
</figure>
<figure>
<img src="images/dataexplorer3.PNG" alt="Dataexplorer" /><figcaption aria-hidden="true">Dataexplorer</figcaption>
</figure>
<h3 id="scoping-the-dataset">Scoping the dataset</h3>
<p>While we wanted a good mix of news sites in our dataset for analysis, we had to be judicious in pruning four sites from our dataset. These were Rice Media, The Online Citizen, TODAY Online and Yahoo SG. These sites were removed for the following reasons: - Rice Media did not publish every day and contributed to a very small amount of articles published in 2020; - The Online Citizen had long a periods of missing data from the months of April 2020 to August 2020; - TODAY Online tended to be similar in style and scope as Channel News Asia (being that they both operated as Mediacorp’s English news websites); - Yahoo SG was removed as they performed primarily as a content aggregator with the bulk of their content republished from news wires such as Reuters.</p>
<p>To further refine the dataset that we wanted to analyze, we decided to set a threshold on engagement data, and include in the dataset, articles with at least 10 interactions. Doing this reduces the number of articles in the dataset by 131,235 (or close to 58%) and removes articles that were: - Removed quickly after A/B testing; - Removed quickly after editorial corrections; - Republished from international news wire agencies and therefore had low to no engagement.</p>
<p>As we are focused with news articles that have some reach, we removed articles with lower than 10 Facebook engagement from our analysis. A remaining 93,116 articles was available for analysis.</p>
<pre class="{r}"><code>test &lt;-Cleaned %&gt;%
  filter(Total&gt;10)%&gt;%
  select(c(1,10))
test</code></pre>
<h3 id="datatext-pre-processing-and-cleaning">DataText Pre-Processing and cleaning</h3>
<p>Before we can begin text processing, we will need to employ text cleaning to reduce noise to optimize results. Examples of <a href="https://towardsdatascience.com/text-cleaning-methods-for-natural-language-processing-f2fc1796e8c7">‘noise’</a> include special characters, punctuation, common words and typographical errors. During this process, words will also be converted to lower case characters so that same words can all be identified by the computer as the same entity. Useful packages for doing this is the StringR function within the <a href="https://stringr.tidyverse.org/articles/stringr.html">TidyVerse package</a>, Spacyr which utilizes Python function using <a href="https://github.com/rstudio/reticulate">Reticulate</a>, <a href="https://towardsdatascience.com/r-packages-for-text-analysis-ad8d86684adb">Quanteda</a>, Qdap or <a href="https://www.worldfullofdata.com/text-mining-analysis-including-full-code-r/">TM</a>. The method we are using below uses the Stringr package. Stringr is a useful package for working with strings and regular expressions using its pattern matching function and can be used for character manipulation to do text pre-processing.</p>
<pre class="{r}"><code>
library(stringr)
#using stringr and textclean for cleaning
media_processed$Cleaned&lt;-tolower(media_explore$Text)%&gt;%#convert to lowercase
  replace_contraction() %&gt;% #lengthening words (eg,isn&#39;t -&gt; is not)
  replace_word_elongation() %&gt;% #reducing informal writing (eg,heyyyyyyy -&gt; hey)
  str_replace_all(&quot;[0-9]&quot;, &quot; &quot;) %&gt;% #removing numbers
  str_replace_all(&quot;[[:punct:]]&quot;,&quot;&quot;)%&gt;%#remove punctuation
  str_replace_all(&quot;covid|wuhan virus&quot;,&quot;coronavirus&quot;)%&gt;%#word substitution
  str_squish()%&gt;% #reduce repeated whitespace 
str_trim#removes whitespace from start and end of string
#check data 
view(media_processed)
#we will first need to create a Dataframe source from a dataframe
media &lt;- DataframeSource(media_explore) 
###################### not in use ############################
#we can now create the corpus using tm 
corpus &lt;- Corpus(media)
#remove words that at not English 
skipWords &lt;- function (x) removeWords (x, stopwords(“english”)) 
#changing all words to lower case
corpus &lt;- tm_map(corpus, FUN = tm_reduce, tmFuns = list (tolower))
#remove 
corpus &lt; - corpus, FUN = tm_reduce, tmFuns = list(skipWords, removePunctuation, stripWhitespace, removeNumbers, stemdocument))
</code></pre>
<p>A popular method in data cleaning for text is the use of Term Frequency – Inverse Document Frequency or <a href="https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089">TD-IDF</a> which is a pre-processing method that helps surface ‘interesting’ terms in a corpus and reduces importance of commonly used words that appear frequently in the corpus. However, as identified earlier, the nature of standardized style of news reports around common events will inevitably engender the occurrence of common terms. These ‘common terms are therefore important and should not be reduced in ‘weightage’ when analyzing a corpus of text. Because of this, we will not be adopting the TF-IDF method for text cleaning for the purposes of this project and will proceed on to the next step, Topic Modeling.</p>
<h2 id="topic-modeling-methods">2.Topic Modeling Methods</h2>
<h3 id="why-latent-dirichlet-allocation-lda">Why Latent Dirichlet Allocation (LDA)</h3>
<p>To help readers make sense of key events or topics in the large corpus of data, the project will take advantage of the Latent Dirichlet Allocation (LDA) model. This is because LDA is a generative statistical model “that allows for sets of observations to be explained by unobserved groups that explain why some part of the data are similar”. The LDA method has also been successfully adopted for other fields such as <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417414005636">banking</a>.</p>
<h3 id="criticisms-of-lda">Criticisms of LDA</h3>
<p>Although LDA has been criticized for issues with <a href="https://advances.sciencemag.org/content/4/7/eaaq1360">overfitting</a> and lacks an intrinsic method for choosing a number of topics it is a method that is extremely advantageous for the purposes of our study. This is because the method itself is unsupervised and allows for the dashboard to assist readers in identifying topics that are <a href="https://medium.datadriveninvestor.com/known-knowns-unknown-knowns-and-unknown-unknowns-b35013fb350d">‘unknown-unknowns’</a> even though some of the topic models derived may not be immediately clear. As we are unable to ‘predict’ news events, we are unable to pre-define topics for analysis and presentation in the snapshot. As the LDA method is unsupervised and can handle ‘unknown-unknowns’, the proposed dashboard is thus scalable and reproducible as it will be able to handle new datasets containing new or future news articles.</p>
<h3 id="different-methods-and-packages-for-lda">Different methods and packages for LDA</h3>
<p>After selecting the LDA method, we identified different methods and packages that can be used. These include the traditional <a href="https://www.tidytextmining.com/topicmodeling.html">LDA</a>, <a href="url%20https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751">word2vec</a> and the newer <a href="https://www.r-bloggers.com/2015/11/analyzing-texts-with-text2vec-package/">text2vec</a>. Both word2vec and text2vec methods build on top of the LDA model and are <a href="https://cran.r-project.org/web/packages/text2vec/vignettes/text-vectorization.html">less resource demanding</a> and has a smaller memory footprint because it does not need to perform a lookup over an associative array. It does this with feature hashing that maps features into a more compact space (crf. <a href="http://alex.smola.org/papers/2009/Weinbergeretal09.pdf">original research paper by Yahoo</a>).</p>
<h3 id="issues-faced">Issues faced</h3>
<p>Creating topic models using TidyText and its associated packages (Quanteda and TM) was not ideal for 220k documents as the document term matrix would be prohibitively large. Each iteration of LDA modeling using this method would take longer (e.g. 5,000 iterations took about 5hrs on our laptops).</p>
<p>We were also not able to properly harness memory allocation packages such as (<a href="https://cran.r-project.org/web/packages/bigmemory/bigmemory.pdf">Big Memory</a> and <a href="https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html">Parallel</a>. The processes were still lengthy even after we removed infrequent words from the Document Term Matrix. More importantly, the results were not easily reproducible as the LDA model is based on random seeds, it would return a different result (if we did not set a seed) after every 5 hours of running it.</p>
<figure>
<img src="images/tidytext%20model.png" alt="Tidy Text Topic Modeling" /><figcaption aria-hidden="true">Tidy Text Topic Modeling</figcaption>
</figure>
<h3 id="package-selected-text2vec">Package Selected: text2Vec</h3>
<p>Due to the reasons outlined above, we proceeded with the Text2Vec package for Topic Modelling. The steps on topic modelling using text2vec can be found below:</p>
<pre class="{r}"><code>#install package 
devtools::install_github(&#39;dselivanov/text2vec
library(text2vec) 
#tokenize words
tokens = media_processed$cleaned) 
tokens = word_tokenizer(tokens)
it = itoken(tokens, ids = media_processed$docid, progressbar = FALSE)
v = create_vocabulary(it)
#remove very common and uncommon words 
v = prune_vocabulary(v, term_count_min = 10, doc_proportion_max = 0.2)
vectorizer = vocab_vectorizer(v)
#constructing a Document Term Matrix 
dtm2 = create_dtm(it, vectorizer, type = &quot;dgTMatrix&quot;)
# Creating LDA for 20 topics
lda_model = LDA$new(n_topics = 20, doc_topic_prior = 0.1, topic_word_prior = 0.01)
doc_topic_distr = 
  lda_model$fit_transform(x = dtm2, n_iter = 1000, 
                          convergence_tol = 0.001, n_check_convergence = 25, 
                          progressbar = FALSE)
# identifying the proportion of word distribution
barplot(doc_topic_distr[1, ], xlab = &quot;topic&quot;, 
        ylab = &quot;proportion&quot;, ylim = c(0, 1), 
        names.arg = 1:ncol(doc_topic_distr))</code></pre>
<figure>
<img src="images/tidytext%20lda.png" alt="Doing this will give the distribution for the topic distribution for the first document" /><figcaption aria-hidden="true">Doing this will give the distribution for the topic distribution for the first document</figcaption>
</figure>
<pre class="{r}"><code>#getting top 10 words for each topic based on lambda 0.4
lda_model$get_top_words(n = 10, topic_number = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 19L, 20L), lambda = 0.4)</code></pre>
<p>We will now get the LDA topic model results, based on 10 keywords for 20 topics using the lambda 0.4.</p>
<figure>
<img src="images/LDA20.PNG" alt="20 Topics" /><figcaption aria-hidden="true">20 Topics</figcaption>
</figure>
<pre class="{r}"><code>#apply learned model to new data 
it = itoken(test$Cleaned[4001:5000], tolower, word_tokenizer, ids = test$docid[4001:5000])
new_dtm =  create_dtm(it, vectorizer, type = &quot;dgTMatrix&quot;)
new_doc_topic_distr = lda_model$transform(new_dtm)
#Check for perplexity. The lower the score, the better
perplexity(new_dtm, topic_word_distribution = lda_model$topic_word_distribution, doc_topic_distribution = new_doc_topic_distr)</code></pre>
<h3 id="visualizing-results">Visualizing Results</h3>
<p>After retrieving the topics from <a href="http://text2vec.org/topic_modeling.html">text2vec</a>, we would now need to visualize the results. One interesting visualization for topic modeling was the termite model created by a team at <a href="http://vis.stanford.edu/papers/termite">Stanford University</a>. As seen in the screenshot below, the visualization is clean yet simple, and clearly communicates the size and overlap of keywords between topics.</p>
<figure>
<img src="images/termite.png" alt="Termite" /><figcaption aria-hidden="true">Termite</figcaption>
</figure>
<p>This visualization below is the alternative using LDAviz.</p>
<p><img src="images/LDAVIZ2.PNG" alt="LDAviz: Browser will not allow local files to be run" /> Visualization below may not be visible in Chrome as chrome does not allow running of <a href="https://stackoverflow.com/questions/39007243/cannot-open-local-file-chrome-not-allowed-to-load-local-resource">local files</a>.</p>
<p>We want to save the topics derived for further analysis using the code below. This will allow engagement data derived from the articles to be visualized in an aggregated fashion as topics, instead of per article (which is not ideal as there are 96k articles).</p>
<pre class="{r}"><code>group_by(day)%&gt;%
add_column(topic = topic ,.before = &#39;Date’))</code></pre>
<h2 id="methods-for-presenting-snapshot">3.Methods for Presenting Snapshot</h2>
<p>To achieve the objective of presenting a useful snapshot or report card of the media situation, we explored different packages such as [SunburstR(<a href="https://cran.r-project.org/web/packages/sunburstR/index.html" class="uri">https://cran.r-project.org/web/packages/sunburstR/index.html</a>), <a href="https://cran.r-project.org/web/packages/ggvis/index.html">GGVIS</a> , <a href="https://cran.r-project.org/web/packages/esquisse/index.html">Esquisse</a> and <a href="https://github.com/AntoineGuillot2/D3partitionR">D3PartitionR</a> which can read large volumes of data quickly (using FREAD).</p>
<figure>
<img src="images/D3.gif" alt="D3PartitionR Example" /><figcaption aria-hidden="true">D3PartitionR Example</figcaption>
</figure>
<p>However, after running some tests, we found the visualizations for SunrburstR and D3Partition to be unsuitable. This is because of the size of the documents found in the corpus being too large to visualize using these methods. The speed of interactions was slow, and the visualization outcomes poor due to the variety of colors used for the range of variables found in the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<p><iframe title="Treemap" src="Treemap.html" width="1200" height="850"></iframe></p>
</div>
<div class="layout-chunk" data-layout="l-body">
<p><iframe title="Circle Treemap" src="CircleTreemap.html" width="1200" height="850"></iframe></p>
</div>
<div class="layout-chunk" data-layout="l-body">
<p><iframe title="Sunburst" src="Sunburst.html" width="1200" height="850"></iframe></p>
</div>
<p>As such, despite the packages ability to quickly read data (eg. using FREAD) and their ability to present topline data in an interactive and easy to understand manner, it was not suitable for the purposes of our project.</p>
<h3 id="objective-1-explore---sorting-through-and-identifying-key-events-in-large-corpus-of-news">3.1.<strong>Objective 1: Explore</strong> - Sorting through and identifying key events in large corpus of news</h3>
<p>The alternative found was using a new package called <a href="https://github.com/kgjerde/corporaexplorer">CorporaExplorer</a>. Using the package creates a Shiny App that allows us to quickly input a corpus of documents that can be easily searched by <a href="https://kgjerde.github.io/corporaexplorer/">date or keyword</a>. The output is an interactive heatmap “where each tile represents one document” as well as each document’s corresponding metadata. Using the data we have loaded, we can easily prepare the corpus for visualization using this package.</p>
<pre class="{r}"><code>install.packages(“corporaexplorer”)
library(corporaexplorer)
#preparing the data 
corpus_explorer &lt;- 
  media_explore,
  date_based_corpus = TRUE,
  grouping_variable = &quot;Topic&quot;, #this is skipped if date is TRUE
  within_group_identifier = &quot;Source&quot;, #this is also skipped if date is TRUE 
  columns_doc_info = c(&quot;Topic&quot;, &quot;Headline&quot;, &quot;URL&quot;, &quot;Source&quot;, &quot;Total&quot;, &quot;Likes&quot;, &quot;Shares&quot;, &quot;Comments&quot;), #appending the relevant metadata from the dataset
  corpus_name = &quot;Local Media Coverage in 2020&quot;, #naming the dashboard
  use_matrix = TRUE, 
  matrix_without_punctuation = TRUE,
  tile_length_range = c(1, 25),
  columns_for_ui_checkboxes = TRUE,</code></pre>
<p>With the data prepared, we can now run the Shiny App to explore the corpus</p>
<pre class="{r}&#39;&#39;`"><code>explore( 
  corpus_explorer,
  search_options = list(optional_info = TRUE), #option for keywords in search
  ui_options = list(font_size = &quot;10px&quot;), #size of font in app
  plot_options = list(max_docs_in_wall_view = 100000) #maximum number of documents in the list 
)</code></pre>
<figure>
<img src="images/Corporaexplorer2.PNG" alt="The screenshot above demonstrates the corporaexplorer using the dataset of local media articles published in 2020" /><figcaption aria-hidden="true">The screenshot above demonstrates the corporaexplorer using the dataset of local media articles published in 2020</figcaption>
</figure>
<p>The Coporaexplorer package is able to handle the 91k articles quickly and allows for readers to search the entire corpus by (up to 5) keywords. Selecting a specific day in the Coporaexplorer plot allows readers to then discover more about the selected article / document. This includes the corresponding engagement data regarding the article’s reach and URL and allows readers to meet the goal of quickly sorting through a large corpus of news events by time, topic and keyword.</p>
<p>More detail regarding the module for Objective 1 can be found at the project blog here.</p>
<h3 id="objective-2-discover---providing-greater-detail-and-context-about-a-topic-news-source">3.2.<strong>Objective 2: Discover</strong> - Providing greater detail and context about a topic / news source</h3>
<h4 id="using-sentiment">3.2.1 USing Sentiment</h4>
<p>The second objective to use statistical methods to provide greater detail and context around each topic and news source can be done through sentiment analysis. This will allow readers to understand the value of the sentiment attached to the topic or media source and observe its changes across time.</p>
<p>There are several sentiment analysis packages available including syuzhet and <a href="https://cran.r-project.org/web/packages/sentimentr/readme/README.html">sentimentr</a>. Lexicons that are available for sentiment analysis include “Bing”, “AFINN” and [“NRC”])(<a href="https://hoyeolkim.wordpress.com/2018/02/25/the-limits-of-the-bing-afinn-and-nrc-lexicons-with-the-tidytext-package-in-r/" class="uri">https://hoyeolkim.wordpress.com/2018/02/25/the-limits-of-the-bing-afinn-and-nrc-lexicons-with-the-tidytext-package-in-r/</a>).</p>
<pre class="{r}&#39;&#39;`"><code>install.packages(“sentimentr”, “GGally”, “glue”, “reshape2”)
library(“sentimentr”, “GGally”, “glue”, “reshape2”)
#unnest tokens for analysis 
media_words &lt;- unnest_tokens(media_explorer, word, text) 
view(media_words) 
#use bing lexicon to get media sentiment 
media_sentiment_new &lt;- media_words %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
  count(source, date, sentiment) %&gt;%
  spread(sentiment, n, fill = 0) %&gt;%
  mutate(sentiment = positive - negative)
#use ggplot to plot sentiment over time 
ggplot(media_sentiment_new, aes(date, sentiment, fill = source)) +
  geom_col(show.legend = FALSE)</code></pre>
<figure>
<img src="images/sentiment%20analysis%20overall.png" alt="Overall sentiment analysis" /><figcaption aria-hidden="true">Overall sentiment analysis</figcaption>
</figure>
<p>Article sentiment was most in late January, presumably about the same time the first cases of COVID-19 were found in Singapore – but later trended upwards towards the end of the year. From this analysis, readers can infer that the overall sentiment and pandemic situation improved over the span of the year.</p>
<p>You can change the sentiment plot to show specific media by using ggplot’s facet wrap feature using the code below:</p>
<pre class="{r}&#39;&#39;`"><code>#use ggplot to plot sentiment over time 
ggplot(media_sentiment_new, aes(date, sentiment, fill = source)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~source, ncol = 2, scales = &quot;free_x&quot;) #use facet to show media sentiment across different sources </code></pre>
<figure>
<img src="images/sentiment%20analysis%20by%20media.png" alt="Overall sentiment analysis by media" /><figcaption aria-hidden="true">Overall sentiment analysis by media</figcaption>
</figure>
<p>Based on the chart, we can see that the Straits Times and Channel News Asia publishes more articles with negative keywords from the ‘Bing’ lexicon. This could also give insight to the type of news in their respective news coverage (e.g. news about accidents, crime, death tend to feature more negative keywords) as full fledged news sites could cover a wider range of news stories compared to lifestyle news focused new sites such as Must Share News. To better understand this hypothesis, we can use the word cloud functions and word structure (network and n-gram) analysis found in the later section of this blog.</p>
<p>We are also able to use word cloud to visualize positive and negative words used most frequently in media coverage.</p>
<figure>
<img src="images/sentiment%20analysis.png" alt="Sentiment Word Cloud" /><figcaption aria-hidden="true">Sentiment Word Cloud</figcaption>
</figure>
<p>As mentioned earlier, the word cloud visualization here is not particularly useful as it provides very little value as to what the words’ context are. In the visualization above, it does a bit more to separate negative and positive words but this can be a bit arbitrary. For instance, “Trump” here is seen as positive when it refers to the verb “trump” rather than the former President Donald Trump.</p>
<p>Finally, we are able to also chart news headline sentiment to the SGX to identify if there are any correlations between news sentiment and SGX stock prices. To do this, we will first need SGX data which can be downloaded from <a href="https://sg.finance.yahoo.com/quote/S68.SI?p=S68.SI&amp;.tsrc=fin-srch">Yahoo Finance</a>.</p>
<pre class="{r}&#39;&#39;`"><code>install.packages(&quot;gridExtra&quot;, &quot;plotly&quot;, &quot;dygraphs&quot;, &quot;xts&quot;, &quot;zoo&quot;)
library (&quot;gridExtra&quot;, &quot;plotly&quot;, &quot;dygraphs&quot;, &quot;xts&quot;, &quot;zoo&quot;)

#read downloaded SGX data
Teststock3 &lt;- read_csv(&quot;Data/sgx.csv&quot;)
#format date
Date=teststock3$Date &lt;- as.Date(as.character(teststock3$Date,&quot;%Y-%m-%d&quot;))
#check date format 
class(Date)
#join sentiment and SGX datasets by date 
teststock3 &lt;- teststock3 %&gt;%
  left_join(media_sentiment_new, by = c(&quot;Date&quot; = &quot;date&quot;))     
view(teststock3)
#convert data to xts format for dygraph
Date=teststock3$Date &lt;- as.xts(ts(start = c(2020-1-1), endc(2020teststock3$Date)
Open=teststock3$Open &lt;- as.numeric(na.locf(teststock3$Open))
Close=teststock3$Close &lt;- as.numeric(na.locf(teststock3$Close))
High=teststock3$High &lt;- as.numeric(na.locf(teststock3$High))
Low=teststock3$Low &lt;- as.numeric(na.locf(teststock3$Low))
Sentiment=teststock3$sentiment &lt;- as.numeric(na.locf(teststock3$sentiment))
#bind coloums and convert to xts format required by Dygraph
z=cbind(Open,Close,High, Low, Sentiment)
newdata=xts(z,Date)
#plot graph using dygraph
dygraph(newdata, main = &quot;SGX VS Sentiment of Local News Headlines&quot;) %&gt;%
  dyEvent(&quot;2020-01-23&quot;, &quot;First COVID-19 Case in SG&quot;, labelLoc=&quot;bottom&quot;)%&gt;% #plotting events
  dyEvent(&quot;2020-01-29&quot;, &quot;First Travel Restrictions to SG&quot;, labelLoc=&quot;bottom&quot;)%&gt;%
  dyEvent(&quot;2020-03-27&quot;, &quot;Circuit Breaker Phase 1 starts&quot;, labelLoc=&quot;bottom&quot;)%&gt;%
  dyEvent(&quot;2020-05-19&quot;, &quot;Circuit Breaker Phase 1 Ends&quot;, labelLoc=&quot;bottom&quot;)%&gt;%
  dyEvent(&quot;2020-07-10&quot;, &quot;Polling Day&quot;, labelLoc=&quot;bottom&quot;)%&gt;%
  dyEvent(&quot;2020-08-09&quot;, &quot;National Day&quot;, labelLoc=&quot;bottom&quot;)%&gt;%
  dyEvent(&quot;2020-11-09&quot;, &quot;Biden confirmed as Winner&quot;, labelLoc=&quot;bottom&quot;)%&gt;%
  dyShading(from = &quot;2020-03-27&quot;, to = &quot;2020-5-19&quot;, color = &quot;#FFE6E6&quot;) %&gt;%
  dyHighlight(highlightCircleSize = 5, 
              highlightSeriesBackgroundAlpha = 0.2,
              hideOnMouseOut = FALSE) %&gt;%
dyRangeSelector()</code></pre>
<div class="layout-chunk" data-layout="l-body">
<p><iframe title="SGX VS Sentiment" src="SGX5.html" width="1200" height="850"></iframe></p>
</div>
<p>The resulting plot from Dygraph provides useful interactive features that allows readers to pan and select the time period for analysis. They are also able to mouseover key data points to derive the corresponding SGX prices. To understand the tangible impact news events and sentiment has on the stock market, we conducted a multiple linear regression to observe the results. The codechunk for this can be found below:</p>
<pre class="{r}&#39;&#39;`"><code>#create columns for testing MLR
allCols &lt;- colnames(teststock3)
regCols &lt;- allCols[!allCols %in% c(&quot;Open&quot;,&quot;High&quot;,&quot;Low&quot;, &quot;Adj Close&quot;)]
regCols &lt;- allCols[!allCols %in% c(&quot;Open&quot;, &quot;High&quot;, &quot;Low&quot;)]
#create regression formula 
regCols &lt;- paste(regCols, collapse = &quot;+&quot;)
regCols &lt;- paste(&quot;Close~&quot;,regCols, collapse = &quot;+&quot;)
regCols &lt;- as.formula(regCols)
#call MLR 
Teststock3.lm &lt;- lm(regCols, data = teststock3) 
Summary(teststock3.lm)</code></pre>
<figure>
<img src="images/mlr%20stock.PNG" alt="MLR Results" /><figcaption aria-hidden="true">MLR Results</figcaption>
</figure>
<p>The results for the multiple regression model demonstrate that there is significant collinearity between negative media sentiment and the closing stock prices of the SGX daily. As seen in the results, news events and headlines should be analyzed in greater detail because they can have very real and tangible impact.</p>
<h4 id="using-wordnetworks">3.2.2 USing WordNetworks</h4>
<p>Another method explored for allowing users to read in greater detail, the different topics and news sources, is the analysis and visualization of word structure. This can be done by analyzing the word graph or word networks relating to the topic or media source. Word analysis using statistical methods can be very use in helping to track and visualize the evolution of <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0122174">news</a>, and demonstrate how differently each media has covered a <a href="https://towardsdatascience.com/measuring-discourse-bias-using-text-network-analysis-9f251be5f6f3">topic</a>.</p>
<p>Using R packages such as tidytext, dplyr, igraph and ggraph, we can <a href="https://www.tidytextmining.com/ngrams.html">plot</a> the word networks related to different topics in the corpus.</p>
<pre class="{r}&#39;&#39;`"><code>install.packages(“tidytext”, “dplyr”, “igraph”, “ggraph”)
library(“tidytext”, “dplyr”, “igraph”, “ggraph”)
#creating bigrams
media_bigrams &lt;- media_explore %&gt;%
  unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n=2)
media_bigrams
#sorting bigrams 
media_bigrams %&gt;%
count(bigram, sort = TRUE)
#splitting bigrams and removing stop words 
bigrams_separated &lt;- media_bigrams %&gt;%
  separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;)
bigrams_filtered &lt;- bigrams_separated %&gt;%
  filter(!word1 %in% stop_words$word) %&gt;%
filter(!word2 %in% stop_words$word)

#new bigram counts 
# new bigram counts:
bigram_counts &lt;- bigrams_filtered %&gt;% 
  count(word1, word2, sort = TRUE)
bigram_counts
#graphing word network  
bigram_counts
bigram_graph &lt;- bigram_counts %&gt;%
  filter(n &gt; 5) %&gt;%
  graph_from_data_frame()
bigram_graph
set.seed(2017)
ggraph(bigram_graph, layout = &quot;fr&quot;) +
  geom_edge_link() +
  geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)</code></pre>
<figure>
<img src="images/wordnetwork.PNG" alt="Word Network" /><figcaption aria-hidden="true">Word Network</figcaption>
</figure>
<p>Using the word network plotted above allows readers to identify the words that were frequently used together and gives readers more context to the topic (ie. GE2020). However, this method is not the most intuitive and its presentation left a lot to be desired.</p>
<p>Referenced earlier in the blog, is Masood’s work that we felt was very useful in visualizing co-occurring words across different media sources. Visualizing this could be very useful as readers can quickly infer if certain keywords or entities have been left out when analyzing topics.</p>
<figure>
<img src="images/cooccurrence.PNG" alt="Co-occurrences across different texts" /><figcaption aria-hidden="true">Co-occurrences across different texts</figcaption>
</figure>
<p>Unfortunately, this visualization of presenting sets is more useful when the number of documents in the text is small. Visualizing this over 96k articles will be less helpful, even after aggregation into different topics. An alternative approach of visualizing co-occurrence is explore in the next section.</p>
<h4 id="using-word-co-occurences">3.2.2 USing Word Co-occurences</h4>
<p>Finally, using the tri-grams identified in the text, we are able to visualize how any two words in a selected corpus is used, where they are similar and where they <a href="https://www.chrisharrison.net/index.php/Visualizations/WebTrigrams">diverge</a>. Research into empirical <a href="https://www.researchgate.net/publication/285764383_Collocations_and_statistical_analysis_of_n-grams_Multiword_expressions_in_newspaper_text">linguistics</a> have identified how the frequency of words occurring together can give insight and meaning to the treatment of a topic and the ‘closeness’ of association between entities. This can help readers understand the context to how words in media coverage was used when compared to <a href="https://www.hvitfeldt.me/blog/visualizing-trigrams-with-the-tidyverse/">each other</a>.</p>
<p>For this segment, we were inspired by the work of <a href="https://www.chrisharrison.net/index.php/Visualizations/WebTrigrams">Chris Harissson</a> and <a href="https://github.com/EmilHvitfeldt">Emil Hvitfeldt</a>. We will need to call on the packages of purrrlyr for this next visualization. The code below is attributed to <a href="https://www.hvitfeldt.me/blog/visualizing-trigrams-with-the-tidyverse/">Emil Hvitfeldt</a>.</p>
<pre class="{r}&#39;&#39;`"><code>install.pacakges(“purrrlyr”)
library(purrrlyr)
n_word &lt;- 20
n_top &lt;- 150
n_gramming &lt;- 3
#creating trigrams
trigrams &lt;- tibble(text = media_explore$Text) %&gt;%
  unnest_tokens(trigram, text, token = &quot;ngrams&quot;, n = n_gramming)
#select the start words you want to compare
start_words &lt;- c(&quot;covid&quot;, &quot;coronavirus&quot;)</code></pre>
<p>As seen in the visualization above, the word network can be elegantly displayed and compared with each other to see how they unfold more often in media coverage. From the visualization, we can infer that the word PAP is more often related to a wider range of words in media coverage compared to WP. We hope to integrate this function as a module in the Shiny Dashboard for the project.</p>
<p>The proposed sketch and detail regarding the module for Objective 2 can be found in the later section of this blog here.</p>
<h3 id="objective-3-detect---providing-alerts-to-unusual-patterns-in-news-analysis">3.4.<strong>Objective 3: Detect</strong> - Providing alerts to unusual patterns in news analysis</h3>
<p>To meet objective 3 for the project, we researched how technology companies such <a href="https://www.theverge.com/2016/11/11/13594338/facebook-acquires-crowdtangle">CrowdTangle</a> and <a href="https://www.newswhip.com/2016/08/spike-predict-viral-stories-update/">Newswhip</a> used engagement figures in order to predict the likelihood articles go viral. Newswhip utilizes a method of measuring <a href="https://www.newswhip.com/2014/01/what-is-social-velocity/">velocity</a> by tracking the speed of engagements and measures if it is overperforming when compared to the average interaction speed of other articles from the same publisher.<br />
<img src="images/anomaly%20detection.png" alt="Anomaly detection in time series - photo credit Analytics Vidhya" /></p>
<p>This can be useful for us to visualize anomalies in time series using packages in <a href="https://www.analyticsvidhya.com/blog/2020/12/a-case-study-to-detect-anomalies-in-time-series-using-anomalize-package-in-r/">R</a>. Sorting this by media type or by topic, can help to identify if there are key articles or events that need to be explored first, amongst the influx of articles that being disseminated at any point of time.</p>
<p>More detail regarding the module for Objective 3 can be found at the project blog here (url)</p>
<h1 id="summary-of-observations-from-exploration-of-r-packages">Summary of observations from exploration of R Packages</h1>
<p>To summarize, we will be adopting packages for three different modules to meet our objectives of helping readers to better understand news events in a large corpus of headlines, create snapshots that are based on rigorous statistical methods to understand quickly the context surrounding a topic and finally to see red-flags / or anomalous instances in the news corpus.</p>
<h1 id="proposed-sketch-of-project-module-2-discovering-topics-and-its-context">Proposed Sketch of Project Module 2: Discovering Topics and it’s context</h1>
<p>Based on the research work, methods and proto-typing found above the proposed dashboard for the Project’s Module that will help readers contextualize news topics and sources can be found in the sketch below.</p>
<figure>
<img src="images/modulesketch.jpg" alt="Sketch for proposed module" /><figcaption aria-hidden="true">Sketch for proposed module</figcaption>
</figure>
<p>The intended module seeks to provide media sentiment using the ‘bing’ lexicon and give insight into topics by allowing them to observe the tri-grams most frequently used with the topic keyword. Users will also be able to select the topic or media source in order to create a ‘snapshot’ that would present them with the relevant information.</p>
<p>Click on the respective links to find out more about modules 1 and 3. The integrated Shiny dashboard for the modules will be presented at a later date.</p>
<h1 id="closing-reflections">Closing Reflections</h1>
<p>While there are many aspects to explore to help make sense of the news corpus, we have selected packages and methods that would best suit a large volume of unstructured data and contain interactive user functions to allow them to quickly navigate the corpus and create snapshots around topics they are interested in.</p>
<p>Future work could include advance methods for dynamic topic modeling, which would be helpful in identifying how a topic evolve across time (e.g. from Wuhan Virus, to Coronavirus to Covid-19) as well as building on word-graphing and word network techniques for the identification of duplicate articles or ‘fake news’. Improvements can also be made to the user experience by customizing CRAN packages that are used for the purposes of this project.</p>
<p>Thank you for reading up to this point.</p>
<p><em>This blog is a data visualization assignment for the MITB programme at the Singapore Management University.</em></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
